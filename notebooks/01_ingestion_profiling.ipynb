{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39bef4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "BASE_DIR = Path.cwd() if Path.cwd().name != \"notebooks\" else Path.cwd().parent\n",
    "sys.path.append(str(BASE_DIR))\n",
    "\n",
    "from src.cleaning import clean_all_files, export_processed\n",
    "from src.validation import validate_dataset\n",
    "from src.metrics import kpis, by_site_month, category_split, peak_days, sqri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54bf4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
      "c:\\hotel-refund-intelligence\\src\\cleaning.py:93: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "df_clean = clean_all_files(BASE_DIR / \"data\" / \"raw\")\n",
    "export_processed(df_clean, BASE_DIR / \"data\" / \"processed\" / \"refunds_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cfb904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: c:\\Projects\\hotel-refund-intelligence\\notebooks\n",
      "cwd exists: True\n",
      "files in cwd: [WindowsPath('c:/Projects/hotel-refund-intelligence/notebooks/01_ingestion_profiling.ipynb'), WindowsPath('c:/Projects/hotel-refund-intelligence/notebooks/02_cleaning_validation.ipynb'), WindowsPath('c:/Projects/hotel-refund-intelligence/notebooks/03_analysis_storytelling.ipynb')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"cwd exists:\", Path(os.getcwd()).exists())\n",
    "print(\"files in cwd:\", list(Path(os.getcwd()).iterdir())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766f1f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BASE_DIR set to: c:\\Projects\\hotel-refund-intelligence\n",
      "✅ DATA_RAW: c:\\Projects\\hotel-refund-intelligence\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# project root = parent of notebooks folder\n",
    "BASE_DIR = Path.cwd()\n",
    "if BASE_DIR.name == \"notebooks\":\n",
    "    BASE_DIR = BASE_DIR.parent\n",
    "\n",
    "# If you run notebook from elsewhere, fallback: search upward for README.md\n",
    "if not (BASE_DIR / \"README.md\").exists():\n",
    "    for p in Path.cwd().parents:\n",
    "        if (p / \"README.md\").exists():\n",
    "            BASE_DIR = p\n",
    "            break\n",
    "\n",
    "DATA_RAW = BASE_DIR / \"data\" / \"raw\"\n",
    "DATA_INTERIM = BASE_DIR / \"data\" / \"interim\"\n",
    "DATA_PROCESSED = BASE_DIR / \"data\" / \"processed\"\n",
    "FIG_DIR = BASE_DIR / \"reports\" / \"figures\"\n",
    "\n",
    "print(\"✅ BASE_DIR set to:\", BASE_DIR)\n",
    "print(\"✅ DATA_RAW:\", DATA_RAW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c98b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\hotel-refund-intelligence\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747cfc51",
   "metadata": {},
   "source": [
    "# 01 — Ingestion & Profiling\n",
    "Project: Hotel\n",
    " Refund Intelligence (Brighton vs Newhaven)\n",
    "\n",
    "Goal:\n",
    "- Load 6 raw CSVs (Brighton/Newheaven x Nov/Dec/Jan)\n",
    "- Add metadata columns: site, file_month (derived from filename)\n",
    "- Run profiling to understand schema, missingness, refund markers, and date fields\n",
    "- Save a combined interim dataset (no cleaning applied yet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb4ce4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../data/raw/Brighton_December_refund.csv'),\n",
       " WindowsPath('../data/raw/Brighton_January_refund.csv'),\n",
       " WindowsPath('../data/raw/Brighton_November_refund.csv'),\n",
       " WindowsPath('../data/raw/Newheaven_December_refund.csv'),\n",
       " WindowsPath('../data/raw/Newheaven_January_refund.csv'),\n",
       " WindowsPath('../data/raw/Newheaven_November_refund.csv')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "RAW_DIR = Path(\"../data/raw\")  # notebooks/ is one level down from project root\n",
    "RAW_FILES = sorted(RAW_DIR.glob(\"*.csv\"))\n",
    "\n",
    "RAW_FILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abfc09dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Projects\\\\hotel-refund-intelligence\\\\notebooks'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad838fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brighton_December_refund.csv -> ('Brighton', 'Dec-2025')\n",
      "Brighton_January_refund.csv -> ('Brighton', 'Jan-2026')\n",
      "Brighton_November_refund.csv -> ('Brighton', 'Nov-2025')\n",
      "Newheaven_December_refund.csv -> ('Newhaven', 'Dec-2025')\n",
      "Newheaven_January_refund.csv -> ('Newhaven', 'Jan-2026')\n",
      "Newheaven_November_refund.csv -> ('Newhaven', 'Nov-2025')\n"
     ]
    }
   ],
   "source": [
    "MONTH_MAP = {\n",
    "    \"november\": \"Nov-2025\",\n",
    "    \"december\": \"Dec-2025\",\n",
    "    \"january\":  \"Jan-2026\",\n",
    "}\n",
    "\n",
    "def parse_metadata_from_filename(filename: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Expected patterns like:\n",
    "    Brighton_November_refund.csv\n",
    "    Newheaven_January_refund.csv\n",
    "    \"\"\"\n",
    "    base = Path(filename).name\n",
    "    parts = base.split(\"_\")\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(f\"Unexpected filename format: {base}\")\n",
    "\n",
    "    site_raw = parts[0].strip()\n",
    "    month_raw = parts[1].strip().lower()\n",
    "\n",
    "    # Standardize site name to match project spec (Brighton/Newhaven)\n",
    "    # NOTE: your file uses 'Newheaven' spelling; we map it to 'Newhaven' as standard.\n",
    "    if site_raw.lower() == \"brighton\":\n",
    "        site = \"Brighton\"\n",
    "    elif site_raw.lower() in [\"newheaven\", \"newhaven\"]:\n",
    "        site = \"Newhaven\"\n",
    "    else:\n",
    "        site = site_raw  # fallback\n",
    "\n",
    "    if month_raw not in MONTH_MAP:\n",
    "        raise ValueError(f\"Month not recognized in filename: {base}\")\n",
    "\n",
    "    file_month = MONTH_MAP[month_raw]\n",
    "    return site, file_month\n",
    "\n",
    "# quick test\n",
    "for f in RAW_FILES:\n",
    "    print(f.name, \"->\", parse_metadata_from_filename(f.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcccb293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133, 56),\n",
       " Index(['IS_INTERNAL_YN', 'INTERNAL_DEBIT', 'INTERNAL_CREDIT', 'FIRST',\n",
       "        'FIRST_DEBIT', 'FIRST_CREDIT', 'SECOND', 'SECOND_DEBIT',\n",
       "        'SECOND_CREDIT', 'THIRD', 'THIRD_DEBIT', 'THIRD_CREDIT', 'EXP_DATE',\n",
       "        'RECEIPT_NO', 'GUEST_FULL_NAME'],\n",
       "       dtype='str'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for f in RAW_FILES:\n",
    "    site, file_month = parse_metadata_from_filename(f.name)\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"site\"] = site\n",
    "    df[\"file_month\"] = file_month\n",
    "    df[\"source_file\"] = f.name  # extra lineage (helpful for audit)\n",
    "    dfs.append(df)\n",
    "\n",
    "combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "combined.shape, combined.columns[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c8aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 133\n",
      "Cols: 56\n",
      "Unnamed columns: ['Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50', 'Unnamed: 51', 'Unnamed: 52']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SECOND                 1.000000\n",
       "THIRD                  1.000000\n",
       "EXP_DATE               1.000000\n",
       "Unnamed: 51            0.977444\n",
       "Unnamed: 52            0.977444\n",
       "Unnamed: 49            0.962406\n",
       "Unnamed: 50            0.962406\n",
       "Unnamed: 48            0.932331\n",
       "Unnamed: 47            0.924812\n",
       "RECEIPT_NO             0.917293\n",
       "MARKET_CODE            0.902256\n",
       "Unnamed: 45            0.894737\n",
       "Unnamed: 46            0.879699\n",
       "USER_NAME              0.864662\n",
       "CC_CODE                0.849624\n",
       "FIRST                  0.218045\n",
       "CURRENCY1              0.172932\n",
       "DEPOSIT_DEBIT          0.165414\n",
       "Unnamed: 43            0.150376\n",
       "INSERT_DATE            0.142857\n",
       "TARGET_RESORT          0.142857\n",
       "Unnamed: 44            0.142857\n",
       "CASHIER_NAME           0.135338\n",
       "TRX_DESC               0.135338\n",
       "PRINT_CASHIER_DEBIT    0.135338\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic schema overview\n",
    "print(\"Rows:\", len(combined))\n",
    "print(\"Cols:\", len(combined.columns))\n",
    "\n",
    "# Columns that look like Unnamed:*\n",
    "unnamed_cols = [c for c in combined.columns if str(c).lower().startswith(\"unnamed:\")]\n",
    "print(\"Unnamed columns:\", unnamed_cols)\n",
    "\n",
    "# Missingness summary (top 25 most-missing columns)\n",
    "missing = combined.isna().mean().sort_values(ascending=False)\n",
    "missing.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7510968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refund rows (by indicator): 65\n",
      "Refund %: 48.87 %\n"
     ]
    }
   ],
   "source": [
    "# Ensure BUSINESS_FORMAT_DATE exists (we'll validate formally in Notebook 02)\n",
    "col = \"BUSINESS_FORMAT_DATE\"\n",
    "if col not in combined.columns:\n",
    "    print(f\"WARNING: {col} not found. Columns available:\", list(combined.columns))\n",
    "else:\n",
    "    refund_mask = combined[col].astype(str).str.contains(\"refund\", case=False, na=False)\n",
    "    print(\"Refund rows (by indicator):\", refund_mask.sum())\n",
    "    print(\"Refund %:\", round(refund_mask.mean() * 100, 2), \"%\")\n",
    "    combined.loc[refund_mask, col].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f05cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS_DATE sample: ['19:10', '26/12/2025', '26/12/2025', '02-Dec-25', '27/12/2025']\n",
      "BUSINESS_TIME sample: ['01/12/2025', 'OTH', 'OTH', '13:44', 'OTH']\n",
      "BUSINESS_FORMAT_DATE sample: ['OTH', 'Accomm. Refund/Correction', 'Accomm. Refund/Correction', '02/12/2025', 'F&B Refund/Correction']\n"
     ]
    }
   ],
   "source": [
    "for candidate in [\"BUSINESS_DATE\", \"BUSINESS_TIME\", \"BUSINESS_FORMAT_DATE\"]:\n",
    "    if candidate in combined.columns:\n",
    "        sample = combined[candidate].dropna().astype(str).head(5).tolist()\n",
    "        print(candidate, \"sample:\", sample)\n",
    "    else:\n",
    "        print(candidate, \"MISSING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f072c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted object columns to string: 43\n",
      "Example: ['IS_INTERNAL_YN', 'INTERNAL_DEBIT', 'INTERNAL_CREDIT', 'RECEIPT_NO', 'GUEST_FULL_NAME', 'TARGET_RESORT', 'TRX_DESC', 'MARKET_CODE', 'BUSINESS_FORMAT_DATE', 'BUSINESS_TIME']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DALVI\\AppData\\Local\\Temp\\ipykernel_21492\\377403670.py:4: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  obj_cols = combined_for_export.select_dtypes(include=[\"object\"]).columns\n"
     ]
    }
   ],
   "source": [
    "combined_for_export = combined.copy()\n",
    "\n",
    "# Convert all object columns to pandas string dtype to avoid pyarrow mixed-type errors\n",
    "obj_cols = combined_for_export.select_dtypes(include=[\"object\"]).columns\n",
    "combined_for_export[obj_cols] = combined_for_export[obj_cols].astype(\"string\")\n",
    "\n",
    "print(\"Converted object columns to string:\", len(obj_cols))\n",
    "print(\"Example:\", list(obj_cols)[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c80146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object columns: 43\n",
      "dtype: object\n",
      "python types seen (top):\n",
      "CASHIER_CREDIT\n",
      "str      71\n",
      "float    62\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DALVI\\AppData\\Local\\Temp\\ipykernel_21492\\1210985226.py:4: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  obj_cols = combined.select_dtypes(include=[\"object\"]).columns.tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0             0\n",
       "1    1090095721\n",
       "2    1090095723\n",
       "3             0\n",
       "4    1091293970\n",
       "5    1056708191\n",
       "6    1075882805\n",
       "7    1052649417\n",
       "8    1052699998\n",
       "9    1056936990\n",
       "Name: CASHIER_CREDIT, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# show object columns and their missingness\n",
    "obj_cols = combined.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(\"Object columns:\", len(obj_cols))\n",
    "\n",
    "# show top 20 object cols with most missing values\n",
    "combined[obj_cols].isna().mean().sort_values(ascending=False).head(20)\n",
    "col = \"CASHIER_CREDIT\"\n",
    "print(\"dtype:\", combined[col].dtype)\n",
    "print(\"python types seen (top):\")\n",
    "print(combined[col].map(lambda x: type(x).__name__).value_counts().head(10))\n",
    "combined[col].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccf9ee6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IS_INTERNAL_YN                str\n",
       "INTERNAL_DEBIT                str\n",
       "INTERNAL_CREDIT               str\n",
       "FIRST                     float64\n",
       "FIRST_DEBIT               float64\n",
       "FIRST_CREDIT              float64\n",
       "SECOND                    float64\n",
       "SECOND_DEBIT              float64\n",
       "SECOND_CREDIT             float64\n",
       "THIRD                     float64\n",
       "THIRD_DEBIT               float64\n",
       "THIRD_CREDIT              float64\n",
       "EXP_DATE                  float64\n",
       "RECEIPT_NO                 string\n",
       "GUEST_FULL_NAME               str\n",
       "TARGET_RESORT                 str\n",
       "TRX_DESC                      str\n",
       "MARKET_CODE                string\n",
       "BUSINESS_FORMAT_DATE          str\n",
       "BUSINESS_TIME                 str\n",
       "BUSINESS_DATE                 str\n",
       "REFERENCE                     str\n",
       "TRX_NO                        str\n",
       "CASHIER_DEBIT                 str\n",
       "CASHIER_CREDIT             string\n",
       "ROOM                       string\n",
       "CREDIT_CARD_SUPPLEMENT     string\n",
       "CURRENCY1                  string\n",
       "TRX_CODE                      str\n",
       "CASHIER_ID                    str\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_for_export = combined.copy()\n",
    "\n",
    "# Convert every object column to pandas \"string\" dtype\n",
    "# This handles mixed floats/strings cleanly.\n",
    "for c in combined_for_export.columns:\n",
    "    if combined_for_export[c].dtype == \"object\":\n",
    "        combined_for_export[c] = combined_for_export[c].astype(\"string\")\n",
    "\n",
    "combined_for_export.dtypes.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7560efee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('../data/interim/combined_raw_with_metadata.parquet'), True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INTERIM_DIR = Path(\"../data/interim\") if Path(\"../data\").exists() else Path(\"data/interim\")\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = INTERIM_DIR / \"combined_raw_with_metadata.parquet\"\n",
    "combined_for_export.to_parquet(out_path, index=False)\n",
    "\n",
    "out_path, out_path.exists()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
